# -*- coding: utf-8 -*-
"""model_notebook_hs_squared_v6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OT0XRsxQzSBRQfHq1a_msrTU2Ih_cXfD
"""

#from google.colab import drive
#drive.mount('/content/drive')
#%%
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np

mpl.style.use("fivethirtyeight")
mpl.rcParams["lines.linewidth"] = 1.5
mpl.rcParams['figure.figsize'] = (10, 5)

from sklearn.preprocessing import StandardScaler, MinMaxScaler
# load data
df = pd.read_pickle("data_omega.pkl")
#df = df[df.G.isin([0, .25])]
df_row = df.copy()

def explode(df, lst_cols, fill_value='', preserve_index=False):
    # make sure `lst_cols` is list-alike
    if (lst_cols is not None
        and len(lst_cols) > 0
        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):
        lst_cols = [lst_cols]
    # all columns except `lst_cols`
    idx_cols = df.columns.difference(lst_cols)
    # calculate lengths of lists
    lens = df[lst_cols[0]].str.len()
    # preserve original index values    
    idx = np.repeat(df.index.values, lens)
    # create "exploded" DF
    res = (pd.DataFrame({
                col:np.repeat(df[col].values, lens)
                for col in idx_cols},
                index=idx)
             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)
                            for col in lst_cols}))
    # append those rows that have empty lists
    if (lens == 0).any():
        # at least one list in cells is empty
        res = (res.append(df.loc[lens==0, idx_cols], sort=False)
                  .fillna(fill_value))
    # revert the original index order
    res = res.sort_index()
    # reset index if requested
    if not preserve_index:        
        res = res.reset_index(drop=True)
    return res


df = explode(df, ["xt", "yt", "t", "xt_dot"])

# Commented out IPython magic to ensure Python compatibility.
# %debug
from sklearn.preprocessing import StandardScaler, MinMaxScaler


from main import SmartDynamicPredictor

# train ratio
TRAIN_RATIO = .2
# Cut transient part
T2CUT = 100
SCALER = StandardScaler
T_WINDOW = 1
VAL_SPLIT = .1

obj = SmartDynamicPredictor(data=df, 
                            train_ratio=TRAIN_RATIO, 
                            transient2cut=T2CUT,
                            scaler=SCALER,
                            val_split=VAL_SPLIT,
                            input_cols=["yt"],
                            output_cols=["xt"]
                            )
data = obj.main(input_cols=["yt"], 
                output_col="xt", 
                t_window=T_WINDOW,
                hs_values=df.hs.unique())

data

df.values.reshape(df.shape[0], len(df.columns))

plt.plot(np.diff(df.yt))

# train ratio
TRAIN_RATIO = .2
# Cut transient part
T2CUT = 100
SCALER = StandardScaler
T_WINDOW = 150
VAL_SPLIT = .1

obj = SmartDynamicPredictor(data=df, 
                            train_ratio=TRAIN_RATIO, 
                            transient2cut=T2CUT,
                            scaler=SCALER,
                            val_split=VAL_SPLIT
                            )
data = obj.main(input_cols=["yt"], 
                output_col="xt", 
                t_window=T_WINDOW,
                hs_values=df.hs.unique())

n_steps = data["n_steps"]
x_train = data["x_train"]
y_train = data["y_train"]
y_test = data["y_test"]
x_test = data["x_test"]
x_val = data["x_val"]
y_val = data["y_val"]
all_data = data["all_data"]
n_features = x_train.shape[2]

# Concatenar os resultados de hs com essa rede atual 
# Estruturar a rede final. Como ????

def plot_time_series(hs, ax1, ax2):
    data_train = obj.df2train[obj.df2train.hs == hs]
    data_test = obj.df2test[obj.df2test.hs == hs]
    #data_val = obj.df2val[obj.df2val.G == g]

    
    ax1.plot(data_train.t[:], data_train.yt)
    ax2.plot(data_train.t[:], data_train.xt)
    
fig, (ax1, ax2) = plt.subplots(2, 1)
for hs in df.hs.unique():
    plot_time_series(hs, ax1, ax2)

from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten
from tensorflow import keras
import tensorflow as tf


optimizer = keras.optimizers.Adam(learning_rate=0.0001)

# definir modelo
model = Sequential()
model.add(Conv1D(filters=20, 
                 kernel_size=4, 
                 activation="relu", 
                 input_shape=(n_steps, n_features)))
model.add(Conv1D(filters=20, 
                 kernel_size=4, 
                 activation="relu", 
                 input_shape=(n_steps, n_features)))
model.add(Flatten())
model.add(Dense(30, activation="relu"))
model.add(Dense(1))
model.compile(optimizer=optimizer, loss="mse")

#model = keras.models.load_model("/content/drive/MyDrive/1.Mestrado/2. Disertação/6. vary_model/hs_vary/keras_model")

# fit model
history = model.fit(x_train, 
                    y_train, 
                    epochs=300, 
                    verbose='auto', 
                    validation_split=0, 
                    validation_data=(x_val, y_val),
                    batch_size=64,
                    shuffle=False)

model.save("/content/drive/MyDrive/1.Mestrado/2. Disertação/6. vary_model/hs_vary/keras_model")

stoppp

#model = keras.models.load_model("/content/drive/MyDrive/1.Mestrado/2. Disertação/6. vary_model/keras_model")

from sklearn.metrics import r2_score
yhat = model.predict(x_train)
r2 = r2_score(obj.scalers["xt"].inverse_transform(yhat), 
              obj.scalers["xt"].inverse_transform(y_train))

print(f"Error R2: {round(r2, 3)}")

r2_results = {}
yhat_results = {}
for idx, hs in enumerate(df.hs.unique()):
    x = all_data[hs]["x"]
    y = all_data[hs]["y"]
    yhat = list(model.predict(x))
    r2_results[hs] = r2_score(obj.scalers["xt"].inverse_transform(yhat), 
                             obj.scalers["xt"].inverse_transform(y))
    yhat_results[hs] = np.array(yhat)

df_row["r2_score"] = r2_results.values()
df_row["yhat"] = list(yhat_results.values())

plt.plot(df_row.hs, 
         df_row.r2_score, 
         color="red"
         )
plt.ylabel("$r^2$")
plt.xlabel("Hs");

df_row.r2_score

import ipywidgets as widgets
hs_const = widgets.Dropdown(options=df.hs.unique(),
                           value=df.hs.unique()[0],
                           description="Hs: ")

def plot_func(hs):
    """ To plot timeseries """
    data1 = list(obj.df2train[obj.df2train.hs == hs].xt)
    data1 += list(obj.df2test[obj.df2test.hs == hs].xt)
    yhat = yhat_results[hs]

    plt.plot(data1[999:], 
             color="blue", 
             zorder=1)
    plt.plot(yhat[:], 
             color="red", 
             zorder=2, 
             alpha=.5);
    plt.ylabel("x(t) [m]")
    #plt.xlabel("Time [s]")

widgets.interactive(plot_func, hs=hs_const)